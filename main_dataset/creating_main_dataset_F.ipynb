{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_dictionary = {\n",
    "              \"BG\"   : [\"Bunge Limited\", \"Agrar\"],\n",
    "    \n",
    "              \"ALSN\" : [\"Allison Transmission\", \"Automobile\"],\n",
    "              \"AN\"   : [\"Autonation\", \"Automobile\"],\n",
    "              \"BMW\"  : [\"BMW\", \"Automobile\"],\n",
    "              \"DAI\"  : [\"Daimler\", \"Automobile\"],\n",
    "              \"GE\"   : [\"General Electric\", \"Automobile\"],\n",
    "              \"TSLA\" : [\"Tesla\", \"Automobile\"],\n",
    "    \n",
    "              \"DB\"   : [\"Deutsche Bank\", \"Banking\"],\n",
    "              \"CBK\"  : [\"Commerzbank\", \"Banking\"],\n",
    "    \n",
    "              \"ABBV\" : [\"Abbvie Inc.\", \"Biotech\"],\n",
    "              \"ACAD\" : [\"Acadia Pharmaceuticals Inc.\", \"Biotech\"],\n",
    "              \"AMGN\" : [\"Amgen Inc.\", \"Biotech\"],\n",
    "              \"BIIB\" : [\"Biogen Inc.\", \"Biotech\"],\n",
    "              \"CRSP\" : [\"Crispr Therapeutics AG\", \"Biotech\"],\n",
    "    \n",
    "              \"10E\"  : [\"Aphria Inc.\", \"Cannabis\"],\n",
    "              \"AGEEF\": [\"Halo Labs Inc.\", \"Cannabis\"],\n",
    "              \"CGC\"  : [\"Canopy Growth\", \"Cannabis\"],\n",
    "              \"CRON\" : [\"Cronos Group\", \"Cannabis\"],\n",
    "              \"TLRY\" : [\"Tilray Inc.\", \"Cannabis\"],\n",
    "              \"ACB\"  : [\"Aurora Cannabis\", \"Cannabis\"],\n",
    "    \n",
    "              \"CLDR\" : [\"Cloudera Inc.\", \"Cloud\"],\n",
    "              \"CRM\"  : [\"Salesforce\", \"Cloud\"],\n",
    "              \"DOCU\" : [\"DocuSign\", \"Cloud\"],\n",
    "              \"NOW\"  : [\"Service Now\", \"Cloud\"],\n",
    "    \n",
    "              \"APX\"  : [\"Appen Limited\", \"Datenverarbeitung\"],\n",
    "              \"D6H\"  : [\"Datagroup\", \"Datenverarbeitung\"],\n",
    "    \n",
    "              \"D\"    : [\"Dominion Energy\", \"Energy\"],\n",
    "              \"386\"  : [\"Sinopec\", \"Energy\"],\n",
    "              \"NEE\"  : [\"NextEra Energy\", \"Energy\"],\n",
    "              \"R6C\"  : [\"Royal Dutch Shell\", \"Energy\"],\n",
    "    \n",
    "              \"DIS\"  : [\"Walt Disney\", \"Entertainment\"],\n",
    "    \n",
    "              \"AAPL\" : [\"Apple Inc.\", \"FANG\"],\n",
    "              \"AMZN\" : [\"Amazon Com Inc.\", \"FANG\"],\n",
    "              \"FB\"   : [\"Facebook Inc.\", \"FANG\"],\n",
    "              \"GOOGL\": [\"Alphabet Inc.\", \"FANG\"],\n",
    "              \"NFLX\" : [\"Netflix Inc.\", \"FANG\"],\n",
    "    \n",
    "              \"PYPL\" : [\"PayPal Inc.\", \"Fintech\"],\n",
    "              \"XAUMF\": [\"Goldmoney Inc.\", \"Fintech\"],\n",
    "              \"SQ\"   : [\"Square Inc.\", \"Fintech\"],\n",
    "    \n",
    "              \"BC\"   : [\"Brunswick Corp.\", \"Tourism\"],\n",
    "              \"RCL\"  : [\"Royal Caribbean Group\", \"Tourism\"],\n",
    "    \n",
    "              \"EA\"   : [\"Electronic Arts Inc.\", \"Gaming\"],\n",
    "              \"GME\"  : [\"Gamestop\", \"Gaming\"],\n",
    "              \"TCEHY\" : [\"Tencent Holding LTD\", \"Gaming\"],\n",
    "    \n",
    "              \"CDW\"  : [\"CDW Corp.\", \"Trade\"],\n",
    "    \n",
    "              \"AGNC\" : [\"AGNC Investment Corp.\", \"Real Estate\"],\n",
    "              \"CBRE\" : [\"CBR Group Inc.\", \"Real Estate\"],\n",
    "              \"MHK\"  : [\"Mohawk Industries\", \"Real Estate\"],\n",
    "              \"EPR\"  : [\"EPR Properties\", \"Real Estate\"],\n",
    "              \"PLD\"  : [\"Prologis Inc.\", \"Real Estate\"],\n",
    "    \n",
    "              \"CFX\"  : [\"Colfax Corporation\", \"Industry\"],\n",
    "              \"DOV\"  : [\"Dover Corp.\", \"Industry\"],\n",
    "              \"MT\"   : [\"Arcelormittal SA.\", \"Industry\"],\n",
    "              \"CLF\"  : [\"Cleveland Cliffs Inc.\", \"Industry\"],\n",
    "              \"SLCA\" : [\"Silicia Holdings Inc.\", \"Industry\"],\n",
    "              \"BAK\"  : [\"Braskem\", \"Industry\"],\n",
    "              \"TKA\"  : [\"Thyssenkrupp AG\", \"Industry\"],\n",
    "              \"SLB\"  : [\"Schlumberger Limited\", \"Industry\"],\n",
    "              \"MMM\"  : [\"3M Company\", \"Industry\"],\n",
    "    \n",
    "              \"9984\" : [\"Softbank Group\", \"Investors\"],\n",
    "              \"BRK.B\": [\"Berkshire Hathaway Inc.\", \"Investors\"],\n",
    "    \n",
    "              \"LMT\"  : [\"Lockheed Martin Corp.\", \"Nuclear Fusion\"],\n",
    "    \n",
    "              \"BATS\" : [\"British American Tobacco\", \"Consumer Products\"],\n",
    "              \"JNJ\"  : [\"Johnson & Johnson\", \"Consumer Products\"],\n",
    "              \"NESN\" : [\"Nestl√©\", \"Consumer Products\"],\n",
    "              \"PG\"   : [\"Procter & Gamble\", \"Consumer Products\"],\n",
    "    \n",
    "              \"BTCUSD\": [\"Bitcoin\", \"Crypto\"],\n",
    "              \"ETHUSD\": [\"Ethereum\", \"Crypto\"],\n",
    "              \"IOTUSD\": [\"Iota\", \"Crypto\"],\n",
    "              \"LINKUSDT\": [\"Chainlink\", \"Crypto\"],\n",
    "    \n",
    "              \"BYND\" : [\"Beyond Meat\", \"Consumer Brands\"],\n",
    "              \"LVMH\" : [\"Louis Vuitton\", \"Consumer Brands\"],\n",
    "              \"TXN\"  : [\"Texas Instruments\", \"Consumer Brands\"],\n",
    "              \"XIACF\": [\"Xiaomi Corp.\", \"Consumer Brands\"],\n",
    "              \"ADS\"  : [\"Adidas AG\", \"Consumer Brands\"],\n",
    "              \"CMG\"  : [\"Chipotle Mexican Grill\", \"Consumer Brands\"],\n",
    "    \n",
    "              \"ISRG\" : [\"Intuitive Surgical Inc.\", \"Medi-Tech\"],\n",
    "    \n",
    "              \"ACIA\" : [\"Acacia Communications Inc.\", \"Network\"],\n",
    "              \"BR\"   : [\"Broadridge Financial Solutions\", \"Network\"],\n",
    "              \"COMM\" : [\"Commscope Holdings\", \"Network\"],\n",
    "              \"M0Y\"  : [\"Mynaric AG\", \"Network\"],\n",
    "    \n",
    "              \"BBY\"  : [\"Best Buy\", \"E-Commerce\"],\n",
    "              \"BABA\" : [\"Alibaba Group\", \"E-Commerce\"],\n",
    "              \"OCDO\" : [\"Ocado Group PLC\", \"E-Commerce\"],\n",
    "              \"SHOP\" : [\"Shopify Inc.\", \"E-Commerce\"],\n",
    "              \"FVRR\" : [\"Fiverr LTD\", \"E-Commerce\"],\n",
    "    \n",
    "              \"ABC\"  : [\"Amerisourcebergen Corp.\", \"Pharma\"],\n",
    "              \"ABT\"  : [\"Abbott Laboratories\", \"Pharma\"],\n",
    "              \"BAS\"  : [\"BASF\", \"Pharma\"],\n",
    "              \"BAYN\" : [\"Bayer AG\", \"Pharma\"],\n",
    "              \"CVS\"  : [\"CVS Healthcare\", \"Pharma\"],\n",
    "              \"DVA\"  : [\"Davita Inc.\", \"Pharma\"],\n",
    "              \"MCK\"  : [\"Mckesson Corp.\", \"Pharma\"],\n",
    "              \"NOVO_B\": [\"Novo Nordisk\", \"Pharma\"],\n",
    "              \"OHI\"  : [\"Omega Healthcare\", \"Pharma\"],\n",
    "    \n",
    "              \"SPCE\" : [\"Virgin Galactic Holdings\", \"Space\"],\n",
    "              \"UFO\"  : [\"Procure ETF\", \"Space\"],\n",
    "    \n",
    "              \"AA\"   : [\"Alcoa Corporation\", \"Raw Materials\"],\n",
    "              \"MPC\"  : [\"Marathon Petroleum\", \"Raw Materials\"],\n",
    "              \"XAUUSD\": [\"Gold\", \"Raw Materials\"],\n",
    "              \"EMPR\" : [\"Empire Petroleum\", \"Raw Materials\"],\n",
    "              \"USOIL\": [\"WTI Crude Oil\", \"Raw Materials\"],\n",
    "              \"LAC\"  : [\"Lithium Americas Corp.\", \"Raw Materials\"],\n",
    "              \"PALL\" : [\"Aberdeen Palladium\", \"Raw Materials\"],\n",
    "              \"NNIC\" : [\"Norilsk Nickel\", \"Raw Materials\"],\n",
    "              \"GOLD\" : [\"Barrick Gold\", \"Raw Materials\"],\n",
    "              \"KL\"   : [\"Kirkland Lake Gold\", \"Raw Materials\"],\n",
    "    \n",
    "              \"AMAT\" : [\"Applied Materials Inc.\", \"Tech/ Chips\"],\n",
    "              \"AMD\"  : [\"Advanced Micro Devices\", \"Tech/ Chips\"],\n",
    "              \"AVGO\" : [\"Broadcom Inc.\", \"Tech/ Chips\"],\n",
    "              \"BIDU\" : [\"Baidu Inc.\", \"Tech/ Chips\"],\n",
    "              \"CDNS\" : [\"Cadence Design Systems\", \"Tech/ Chips\"],\n",
    "              \"IFX\"  : [\"Infineon Tech AG\", \"Tech/ Chips\"],\n",
    "              \"INTC\" : [\"Intel Corp.\", \"Tech/ Chips\"],\n",
    "              \"NVDA\" : [\"Nvidia Corp.\", \"Tech/ Chips\"],\n",
    "              \"ORCL\" : [\"Oracle Corp.\", \"Tech/ Chips\"],\n",
    "              \"QCOM\" : [\"Qualcomm Inc.\", \"Tech/ Chips\"],\n",
    "              \"SNAP\" : [\"Snap Inc.\", \"Tech/ Chips\"],\n",
    "              \"WB\"   : [\"Weibo Corp.\", \"Tech/ Chips\"],\n",
    "              \"WDC\"  : [\"Western Digital Corp.\", \"Tech/ Chips\"],\n",
    "              \"MSFT\" : [\"Microsoft Corp.\", \"Tech/ Chips\"],\n",
    "              \"ASML\" : [\"ASML Holding\", \"Tech/ Chips\"],\n",
    "              \"TSM\"  : [\"Taiwan Semiconductor\", \"Tech/ Chips\"],\n",
    "    \n",
    "              \"2318\" : [\"Ping An\", \"Insurance\"],\n",
    "              \"ACGL\" : [\"Arch Capital Group\", \"Insurance\"],\n",
    "              \"AON\"  : [\"Aon PLC\", \"Insurance\"],\n",
    "    \n",
    "              \"D7G\"  : [\"Nel Asa\", \"Hydrogen\"],\n",
    "              \"BLDP\" : [\"Ballard Power\", \"Hydrogen\"],\n",
    "              \"27W\"  : [\"Powercell Sweden\", \"Hydrogen\"],\n",
    "              \"LIN\"  : [\"Linde PLC\", \"Hydrogen\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name/ Sector Label Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_sectors(csv, directory):\n",
    "    \n",
    "    if f\"{csv}\".startswith(\"BATS\"):\n",
    "        \n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[5:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"BITFINEX\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[9:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"BITMEX\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[7:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"BITSTAMP\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[9:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"EURONEXT\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[13:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"FWB\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[8:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"HKEX\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[9:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"LSE\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[8:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"MIL\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[8:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"OANDA\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[6:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"OMXCOP\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[11:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"OTC\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[8:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"TSE\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[8:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"TVC\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[4:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short][1]\n",
    "\n",
    "    elif f\"{csv}\".startswith(\"XETR\"):\n",
    "\n",
    "        df_stock = pd.read_csv(direc + f\"{csv}\")\n",
    "        csv_name = csv\n",
    "        stock_short = csv_name[9:csv_name.find(\",\")]\n",
    "        df_stock[\"name\"] = stock_dictionary[stock_short][0]\n",
    "        df_stock[\"sector\"] = stock_dictionary[stock_short]\n",
    "            \n",
    "            \n",
    "    \n",
    "    return df_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_format(df):\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry Column Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entry_column(df):\n",
    "    \n",
    "    df[\"entry\"] = \"\"\n",
    "    for i, row in df.iterrows():\n",
    "        df.at[i, \"entry\"] = df.at[i, \"high\"] + (df.at[i, \"high\"] * 0.002)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop_Loss Column Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stop_loss_column(df):\n",
    "    df[\"stop_loss\"] = \"\"\n",
    "    for i, row in df.iterrows():\n",
    "        if df.at[i, \"close\"] < df.at[i, \"open\"]:\n",
    "            df.at[i, \"stop_loss\"] = df.at[i, \"close\"] #- (df.at[i, \"close\"] * 0.0001)\n",
    "    \n",
    "        else:\n",
    "            df.at[i, \"stop_loss\"] = df.at[i, \"open\"] #- (df.at[i, \"open\"] * 0.0001)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BullishPB Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bullishPB(df):\n",
    "    \n",
    "    diffOC = (df[\"open\"] - df[\"close\"])\n",
    "    diffCO = (df[\"close\"] - df[\"open\"])\n",
    "    diffCM = (df[\"close\"] - df[\"low\"])\n",
    "    diffOM = (df[\"open\"] - df[\"low\"])\n",
    "    diffHC = (df[\"high\"] - df[\"close\"])\n",
    "    diffOL = (df[\"open\"] - df[\"low\"])\n",
    "    diffHO = (df[\"high\"] - df[\"open\"])\n",
    "    diffCL = (df[\"close\"] - df[\"low\"])\n",
    "    \n",
    "    bullishPB = (diffOC <= (diffCM * 0.9)) & (df[\"close\"] < df[\"open\"]) & (diffHO < diffCL) & (diffHO < (diffCL*0.7)) | (diffCO <= (diffOM * 0.9)) & (df[\"open\"] < df[\"close\"]) & (diffHC < diffOL) & (diffHC < (diffOL*0.65))\n",
    "    bullishPB = pd.DataFrame(bullishPB)\n",
    "    bullishPB = bullishPB[0].tolist()\n",
    "    df[\"bullishPB\"] = bullishPB\n",
    "    df_bullishPB = df[df[\"bullishPB\"] == True]\n",
    "\n",
    "    return df_bullishPB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open/Missed, Win/Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_dataframe(df_PB, df):\n",
    "    \n",
    "    label_list = []\n",
    "    label_list_wl = []\n",
    "    for i, row in df_PB.iterrows():\n",
    "        idx_list =[]\n",
    "        for j in range(1,4): #Create List with 3 following Days where the Trade needs to be triggered\n",
    "            idx_list.append(i + j)\n",
    "    \n",
    "    #########################    \n",
    "    \n",
    "        t_Day = 0            #Create t_Day where the Trade was triggered\n",
    "        opening_counts = 0   #As soon as the count jumps on 1, the trade was triggered on that day.\n",
    "        for t in idx_list:\n",
    "            try:\n",
    "                \n",
    "                if opening_counts == 1:\n",
    "                    break\n",
    "    \n",
    "                elif df.at[t, \"high\"] > df.at[i, \"high\"]:\n",
    "                    opening_counts += 1\n",
    "                    t_Day += t            #t_Day = Trigger Day\n",
    "                   \n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "            except KeyError:\n",
    "                break\n",
    "    \n",
    "        if opening_counts == 1:\n",
    "            label_list.append(\"open\")\n",
    "    \n",
    "        else:\n",
    "            label_list.append(\"missed\")\n",
    "            label_list_wl.append(\"missed\")\n",
    "            continue\n",
    "        \n",
    "                   #continue, because when the trade wasnt triggered, we can stop here and move to the next one\n",
    "    ########################\n",
    "    \n",
    "        test_days_list = []           #List of only the Days where a trade was triggered + 75 Days in the future.\n",
    "        for k in range(0,76):         #Loop to create the 75 Days after t_Day.\n",
    "            test_days_list.append(t_Day + k)\n",
    "    \n",
    "    ####################### \n",
    "        \n",
    "        win_loss_list = []\n",
    "        for d in test_days_list:  #d is one day in tf(timeframe, 75 days from trigger Day)\n",
    "            try:\n",
    "                if ((df.at[d, \"open\"] < df.at[i, \"entry\"]) & (df.at[d, \"close\"] > df.at[i, \"entry\"])):\n",
    "                    win_loss_list.append(\"still on\")\n",
    "                    continue\n",
    "    \n",
    "                elif ((df.at[i, \"close\"] < df.at[i, \"open\"]) & (df.at[d, \"low\"] < df.at[i, \"stop_loss\"])) | ((df.at[i, \"close\"] > df.at[i, \"open\"]) & (df.at[d, \"low\"] < df.at[i, \"stop_loss\"])):\n",
    "                        win_loss_list.append(\"loss\")\n",
    "    \n",
    "                elif ((df.at[i, \"close\"] < df.at[i, \"open\"]) & (df.at[d, \"high\"] >= (((df.at[i, \"entry\"] - df.at[i, \"stop_loss\"]) * 10) + df.at[i, \"entry\"]))) | ((df.at[i, \"close\"] > df.at[i, \"open\"]) & (df.at[d, \"high\"] >= (((df.at[i, \"entry\"] - df.at[i, \"stop_loss\"]) * 10) + df.at[i, \"entry\"]))):\n",
    "                        win_loss_list.append(\"win\")\n",
    "    \n",
    "                else:\n",
    "                    win_loss_list.append(\"still on\")\n",
    "    \n",
    "            except (KeyError, ValueError):\n",
    "                \n",
    "                if  ((df.at[df.index[-1], \"open\"] < df.at[i, \"entry\"]) & (df.at[df.index[-1], \"close\"] > df.at[i, \"entry\"])):\n",
    "                    win_loss_list.append(\"still on\")\n",
    "                    continue\n",
    "    \n",
    "                elif ((df.at[i, \"close\"] < df.at[i, \"open\"]) & (df.at[df.index[-1], \"low\"] < df.at[i, \"stop_loss\"])) | ((df.at[i, \"close\"] > df.at[i, \"open\"]) & (df.at[df.index[-1], \"low\"] < df.at[i, \"stop_loss\"])):\n",
    "                    win_loss_list.append(\"loss\")\n",
    "    \n",
    "                elif ((df.at[i, \"close\"] < df.at[i, \"open\"]) & (df.at[df.index[-1], \"high\"] >= (((df.at[i, \"entry\"] - df.at[i, \"stop_loss\"]) * 10) + df.at[i, \"entry\"]))) | ((df.at[i, \"close\"] > df.at[i, \"open\"]) & (df.at[df.index[-1], \"high\"] >= (((df.at[i, \"entry\"] - df.at[i, \"stop_loss\"]) * 10) + df.at[i, \"entry\"]))):\n",
    "                    win_loss_list.append(\"win\")\n",
    "    \n",
    "                else:\n",
    "                    win_loss_list.append(\"still on\")\n",
    "        \n",
    "    #######################\n",
    "        w_count = 0\n",
    "        l_count = 0     \n",
    "        for value in win_loss_list:\n",
    "    \n",
    "            if (w_count == 1) | (l_count == 1):\n",
    "                break\n",
    "    \n",
    "            elif value == \"loss\":\n",
    "                l_count += 1\n",
    "    \n",
    "            elif value == \"win\":\n",
    "                w_count += 1\n",
    "           \n",
    "        if (w_count == 0) & (l_count == 0):\n",
    "            label_list_wl.append(\"still on\")\n",
    "    \n",
    "        elif w_count == 1:\n",
    "            label_list_wl.append(\"win\")\n",
    "    \n",
    "        elif l_count == 1:\n",
    "            label_list_wl.append(\"loss\")\n",
    "            \n",
    "    #########################\n",
    "    \n",
    "    df_PB[\"triggered\"] = label_list\n",
    "    df_PB[\"win_loss\"] = label_list_wl\n",
    "    \n",
    "    \n",
    "    return df_PB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = \"/Users/admin/Desktop/spearmint-vector-student-code/Final_Project/stock_data/Test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(directory):\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for csv in os.listdir(directory):\n",
    "        if not csv.startswith('.'):\n",
    "            print(csv)\n",
    "    \n",
    "            df_stock = get_name_sectors(csv, directory)    #Label Trades with Name and Sector\n",
    "    \n",
    "            df_stock = get_datetime_format(df_stock)    #Datetime Format\n",
    "                \n",
    "            df_stock = create_entry_column(df_stock)\n",
    "                \n",
    "            df_stock = create_stop_loss_column(df_stock)\n",
    "    \n",
    "            df_bullishPB = find_bullishPB(df_stock)  #Extract only the bullish PinBars from Dataframe\n",
    "    \n",
    "            df_bullishPB = get_final_dataframe(df_bullishPB, df_stock) #Final Dataframe with win/loss labels\n",
    "    \n",
    "            df_list.append(df_bullishPB)\n",
    "    \n",
    "        \n",
    "    result = pd.concat(df_list)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATS_AGEEF, 1D.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATS_BIDU, 1D.csv\n",
      "BATS_ABC, 1D.csv\n",
      "BATS_PALL, 1D.csv\n",
      "BATS_9984, 1D.csv\n",
      "BATS_PG, 1D.csv\n",
      "BATS_DIS, 1D.csv\n",
      "BATS_LVMH, 1D.csv\n",
      "BATS_INTC, 1D.csv\n",
      "BATS_CDNS, 1D.csv\n",
      "BATS_DAI, 1D.csv\n",
      "BATS_SNAP, 1D.csv\n",
      "BATS_BIIB, 1D.csv\n",
      "BATS_CRSP, 1D.csv\n",
      "BATS_XAUUSD, 1D.csv\n",
      "BATS_ALSN, 1D.csv\n",
      "BATS_MMM, 1D.csv\n",
      "BATS_MPC, 1D.csv\n",
      "BATS_BLDP, 1D.csv\n",
      "BATS_D7G, 1D.csv\n",
      "BATS_MT, 1D.csv\n",
      "BATS_EPR, 1D.csv\n",
      "BATS_R6C, 1D.csv\n",
      "BATS_TSLA, 1D.csv\n",
      "BATS_ASML, 1D.csv\n",
      "BATS_ACB, 1D.csv\n",
      "BATS_BYND, 1D.csv\n",
      "BATS_BMW, 1D.csv\n",
      "BATS_TXN, 1D.csv\n",
      "BATS_GME, 1D.csv\n",
      "BATS_ORCL, 1D.csv\n",
      "BATS_BG, 1D.csv\n",
      "BATS_MSFT, 1D.csv\n",
      "BATS_BR, 1D.csv\n",
      "BATS_NEE, 1D.csv\n",
      "BATS_NFLX, 1D.csv\n",
      "BATS_AA, 1D.csv\n",
      "BATS_ISRG, 1D.csv\n",
      "BATS_AMD, 1D.csv\n",
      "BATS_BAK, 1D.csv\n",
      "BATS_CGC, 1D.csv\n",
      "BATS_JNJ, 1D.csv\n",
      "BATS_CVS, 1D.csv\n",
      "BATS_MHK, 1D.csv\n",
      "BATS_FB, 1D.csv\n",
      "BATS_ABT, 1D.csv\n",
      "BATS_ETHUSD, 1D.csv\n",
      "BATS_AMGN, 1D.csv\n",
      "BATS_UFO, 1D.csv\n",
      "BATS_GOLD, 1D.csv\n",
      "BATS_AGNC, 1D.csv\n",
      "BATS_BBY, 1D.csv\n",
      "BATS_MCK, 1D.csv\n",
      "BATS_XIACF, 1D.csv\n",
      "BATS_TSM, 1D.csv\n",
      "BATS_BC, 1D.csv\n",
      "BATS_CMG, 1D.csv\n",
      "BATS_M0Y, 1D.csv\n",
      "BATS_BAS, 1D.csv\n",
      "BATS_EA, 1D.csv\n",
      "BATS_OHI, 1D.csv\n",
      "BATS_ACAD, 1D.csv\n",
      "BATS_SPCE, 1D.csv\n",
      "BATS_DOCU, 1D.csv\n",
      "BATS_DOV, 1D.csv\n",
      "BATS_AVGO, 1D.csv\n",
      "BATS_SLB, 1D.csv\n",
      "BATS_PYPL, 1D.csv\n",
      "BATS_ADS, 1D.csv\n",
      "BATS_D6H, 1D.csv\n",
      "BATS_10E, 1D.csv\n",
      "BATS_BRK.B, 1D.csv\n",
      "BATS_KL, 1D.csv\n",
      "BATS_WB, 1D.csv\n",
      "BATS_RCL, 1D.csv\n",
      "BATS_BABA, 1D.csv\n",
      "BATS_WDC, 1D.csv\n",
      "BATS_BTCUSD, 1D.csv\n",
      "BATS_LAC, 1D.csv\n",
      "BATS_BATS, 1D.csv\n",
      "BATS_DVA, 1D.csv\n",
      "BATS_CBK, 1D.csv\n",
      "BATS_QCOM, 1D.csv\n",
      "BATS_27W, 1D.csv\n",
      "BATS_IFX, 1D.csv\n",
      "BATS_AMAT, 1D.csv\n",
      "BATS_AON, 1D.csv\n",
      "BATS_CLF, 1D.csv\n",
      "BATS_LMT, 1D.csv\n",
      "BATS_NOVO_B, 1D.csv\n",
      "BATS_TLRY, 1D.csv\n",
      "BATS_APX, 1D.csv\n",
      "BATS_TCEHY, 1D.csv\n",
      "BATS_ACGL, 1D.csv\n",
      "BATS_LINKUSDT, 1D.csv\n",
      "BATS_TKA, 1D.csv\n",
      "BATS_D, 1D.csv\n",
      "BATS_DB, 1D.csv\n",
      "BATS_ACIA, 1D.csv\n",
      "BATS_XAUMF, 1D.csv\n",
      "BATS_CFX, 1D.csv\n",
      "BATS_OCDO, 1D.csv\n",
      "BATS_CDW, 1D.csv\n",
      "BATS_CLDR, 1D.csv\n",
      "BATS_LIN, 1D.csv\n",
      "BATS_NOW, 1D.csv\n",
      "BATS_AAPL, 1D.csv\n",
      "BATS_ABBV, 1D.csv\n",
      "BATS_SLCA, 1D.csv\n",
      "BATS_SQ, 1D.csv\n",
      "BATS_FVRR, 1D.csv\n",
      "BATS_GOOGL, 1D.csv\n",
      "BATS_CRON, 1D.csv\n",
      "BATS_386, 1D.csv\n",
      "BATS_AN, 1D.csv\n",
      "BATS_BAYN, 1D.csv\n",
      "BATS_COMM, 1D.csv\n",
      "BATS_USOIL, 1D.csv\n",
      "BATS_NVDA, 1D.csv\n",
      "BATS_PLD, 1D.csv\n",
      "BATS_NESN, 1D.csv\n",
      "BATS_NNIC, 1D.csv\n",
      "BATS_CRM, 1D.csv\n",
      "BATS_AMZN, 1D.csv\n",
      "BATS_SHOP, 1D.csv\n",
      "BATS_GE, 1D.csv\n",
      "BATS_IOTUSD, 1D.csv\n",
      "BATS_2318, 1D.csv\n",
      "BATS_CBRE, 1D.csv\n",
      "CPU times: user 12min 13s, sys: 9.95 s, total: 12min 23s\n",
      "Wall time: 14min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "final_df = transform_data(direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"/Users/admin/Desktop/spearmint-vector-student-code/Final_Project/final_df_10x_csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
